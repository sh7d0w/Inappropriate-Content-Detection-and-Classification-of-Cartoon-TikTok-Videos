{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-Z_X6UefF0L"
      },
      "outputs": [],
      "source": [
        "!pip -q install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV3UY8rumcgj",
        "outputId": "1c96d01b-29e9-4623-b515-241165474b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing the required libraries**"
      ],
      "metadata": {
        "id": "ZPVgPMSh8csw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import ArrayType, FloatType\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5B5LA3KvNBb",
        "outputId": "c97a21a1-ce87-4779-f888-ee5b6c1f1d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Spark Session**"
      ],
      "metadata": {
        "id": "QMQX_FtDTWPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Setup Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"VideoClassification\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = 75\n",
        "BATCH_SIZE = 20\n",
        "EPOCHS = 10\n",
        "MAX_SEQ_LENGTH = 16\n",
        "NUM_FEATURES = 2048\n",
        "\n",
        "# Load and broadcast the model\n",
        "model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3), pooling='avg')\n",
        "bc_model = spark.sparkContext.broadcast(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVmsZJG0vQ6n",
        "outputId": "85c6ace9-6c48-40bc-dd79-00e94986ce02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extracting Frames**"
      ],
      "metadata": {
        "id": "rb4TqZdJTiKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load and preprocess video data\n",
        "def preprocess_frames(video_path, frame_rate=1):\n",
        "    frames = []  # Placeholder for extracted frames\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    skip_frames_window = max(int(video_frames_count / MAX_SEQ_LENGTH), 1)\n",
        "\n",
        "    for frame_counter in range(MAX_SEQ_LENGTH):\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "        success, frame = video_reader.read()\n",
        "        if not success:\n",
        "            break\n",
        "        resized_frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
        "        normalized_frame = resized_frame / 255.0\n",
        "        frame_list = normalized_frame.astype(np.float32).tolist()\n",
        "        frames.append(frame_list)\n",
        "\n",
        "    while len(frames) < MAX_SEQ_LENGTH:\n",
        "        frames.append(np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.float32).tolist())\n",
        "\n",
        "    video_reader.release()\n",
        "    return frames\n",
        "\n",
        "# Function to extract features using the broadcasted MobileNetV2 model\n",
        "def extract_features(frames):\n",
        "    frames_array = np.array(frames)\n",
        "    model = bc_model.value  # Use the broadcasted model\n",
        "    features = model.predict(frames_array)\n",
        "    return features\n",
        "\n",
        "# Function to save features to a Parquet file\n",
        "def save_features_to_parquet(features, output_path):\n",
        "    df = pd.DataFrame(features)\n",
        "    df.to_parquet(output_path, index=False)\n",
        "\n",
        "# Processing function\n",
        "def process_video(video_path, output_directory, class_label):\n",
        "    frames = preprocess_frames(video_path)\n",
        "    features = extract_features(frames)\n",
        "    output_filename = f\"{os.path.splitext(os.path.basename(video_path))[0]}_class{class_label}.parquet\"\n",
        "    output_path = os.path.join(output_directory, output_filename)\n",
        "    save_features_to_parquet(features, output_path)\n",
        "    return (output_path, class_label)\n"
      ],
      "metadata": {
        "id": "9Ao5mC8jvVZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories\n",
        "video_directories = [\n",
        "    \"/content/drive/MyDrive/BigData/Class 0 - Safe\",\n",
        "    \"/content/drive/MyDrive/BigData/Class 1 - Fantasy Violence\",\n",
        "    \"/content/drive/MyDrive/BigData/Class 2 - Sex, Nudity\"\n",
        "]\n",
        "output_directory = \"/content/drive/MyDrive/BigData/Test\"\n",
        "\n",
        "# Collect all video file paths with their class labels\n",
        "video_paths = []\n",
        "for class_label, video_directory in enumerate(video_directories):\n",
        "    video_files = [os.path.join(video_directory, video_file) for video_file in os.listdir(video_directory) if video_file.endswith(('.mp4', '.avi'))]\n",
        "    for video_file in video_files:\n",
        "        video_paths.append((video_file, class_label))\n",
        "\n",
        "# Create an RDD from the video paths\n",
        "video_paths_rdd = spark.sparkContext.parallelize(video_paths)\n",
        "\n",
        "# Process videos in parallel\n",
        "results = video_paths_rdd.map(lambda video_path_label: process_video(video_path_label[0], output_directory, video_path_label[1])).collect()\n",
        "\n",
        "\n",
        "print(\"Results: \", results)\n"
      ],
      "metadata": {
        "id": "ojC7gHnNvfEK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b17f868f-fbe1-4879-a9d3-9d47f0eecd19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:  [('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part13_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part3_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part5_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part17_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part14_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part4_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part2_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part1_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part9_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part0_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 3.mp4part11_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part0_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 3.mp4part10_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part11_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part14_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part18_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 3.mp4part5_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 3.mp4part4_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 3.mp4part9_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part12_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part4_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part18_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part0_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part21_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part2_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part5_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part20_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part16_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part15_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part1_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part11_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part10_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 17.mp4part1_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 17.mp4part0_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part9_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 17.mp4part3_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part8_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 17.mp4part2_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part7_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part6_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 17.mp4part12_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 20.mp4part0_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 17.mp4part9_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 17.mp4part11_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 17.mp4part10_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 17.mp4part5_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 17.mp4part7_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 20.mp4part3_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 17.mp4part8_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 20.mp4part2_class0.parquet', 0), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part10_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part16_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part15_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part8_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part12_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 3.mp4part0_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part6_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 3.mp4part1_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part7_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 1.mp4part11_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 3.mp4part2_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 3.mp4part6_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part1_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part3_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 3.mp4part7_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 3.mp4part8_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part5_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 3.mp4part3_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part4_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part2_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part6_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part3_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part13_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part19_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part17_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part8_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part7_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part9_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 4.mp4part10_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part12_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part19_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part20_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part14_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part21_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part16_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part13_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part15_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part17_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 17.mp4part4_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 7.mp4part18_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 20.mp4part5_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 20.mp4part6_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 42.mp4part12_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 42.mp4part5_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 47.mp4part2_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 20.mp4part1_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 47.mp4part0_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 39.mp4part3_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 47.mp4part3_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Copy of RandomCN 17.mp4part6_class1.parquet', 1), ('/content/drive/MyDrive/BigData/Test/Video_1_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/simpson17.mp4part0_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/simpson745.mp4part0_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/simpson745.mp4part5_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/simpson745.mp4part4_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/simpson936.mp4part7_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/simpson994.mp4part2_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/RandomCN 117.mp4part3_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/RandomCN 377.mp4part7_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/RandomCN 377.mp4part6_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/RandomCN 68.mp4part0_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/RandomCN 68.mp4part1_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/RandomCN 874.mp4part2_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/rnm5.mp4part0_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/rnm733.mp4part0_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/rnm733.mp4part2_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/rnm733.mp4part1_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/rnm733.mp4part3_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/rnm848.mp4part1_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/rnm989.mp4part0_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/rnm989.mp4part1_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/rnmt24.mp4part0_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/rnmt37.mp4part1_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/rnmt435.mp4part3_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/rnmt501.mp4part0_class2.parquet', 2), ('/content/drive/MyDrive/BigData/Test/rnmt984.mp4part0_class2.parquet', 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Encoding and Splitting Training-Testing Sets**"
      ],
      "metadata": {
        "id": "2ZsFqvsnzvkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Extract features and labels from the results\n",
        "features_list = []\n",
        "labels_list = []\n",
        "\n",
        "for result in results:\n",
        "    features_path, label = result\n",
        "    features = pd.read_parquet(features_path).values\n",
        "    features_list.append(features)\n",
        "    labels_list.append(label)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "features = np.array(features_list)\n",
        "labels = np.array(labels_list)\n",
        "\n",
        "# Ensure features have the correct shape for LSTM input\n",
        "features = np.reshape(features, (features.shape[0], features.shape[1], -1))\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Save the split data\n",
        "np.save('/content/drive/MyDrive/BigData/X_train.npy', X_train)\n",
        "np.save('/content/drive/MyDrive/BigData/X_test.npy', X_test)\n",
        "np.save('/content/drive/MyDrive/BigData/y_train.npy', y_train)\n",
        "np.save('/content/drive/MyDrive/BigData/y_test.npy', y_test)\n",
        "\n",
        "print(\"Data processing and splitting completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTFerGfEz0oY",
        "outputId": "b44ab28d-701a-40b8-c0cc-6d49c13580e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data processing and splitting completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape,y_train.shape )\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krj30gq_2VyB",
        "outputId": "2dfd1dd0-49d3-4ba9-988c-f23eb6653b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(113, 16, 1280) (113,)\n",
            "(13, 16, 1280) (13,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7tC5bXKQLit",
        "outputId": "438b3169-c113-4aef-98b3-88efaa65accb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1.0606327e+00, 0.0000000e+00, 1.7031278e-01, ...,\n",
              "         5.8634591e-01, 0.0000000e+00, 4.8865478e-02],\n",
              "        [2.5613976e-01, 0.0000000e+00, 1.7089987e-01, ...,\n",
              "         2.0910603e-01, 0.0000000e+00, 2.8398398e-01],\n",
              "        [6.3855624e-01, 0.0000000e+00, 7.4252551e-03, ...,\n",
              "         4.9017906e-02, 4.4912466e-01, 4.5948696e-01],\n",
              "        ...,\n",
              "        [1.4702004e+00, 6.2738791e-02, 1.5029595e+00, ...,\n",
              "         0.0000000e+00, 1.7512474e+00, 4.6759129e-02],\n",
              "        [1.2162323e+00, 6.5420115e-01, 1.7532545e+00, ...,\n",
              "         0.0000000e+00, 7.5528002e-01, 0.0000000e+00],\n",
              "        [4.8062414e-01, 7.9621263e-02, 1.6409785e+00, ...,\n",
              "         0.0000000e+00, 1.8228166e-01, 0.0000000e+00]],\n",
              "\n",
              "       [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
              "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "        [0.0000000e+00, 7.0095319e-01, 0.0000000e+00, ...,\n",
              "         0.0000000e+00, 1.1166382e-01, 6.5884691e-01],\n",
              "        [0.0000000e+00, 7.0277110e-02, 8.8806796e-01, ...,\n",
              "         1.8691438e-01, 3.7489903e-01, 2.3196353e-01],\n",
              "        ...,\n",
              "        [0.0000000e+00, 7.9889733e-01, 0.0000000e+00, ...,\n",
              "         0.0000000e+00, 0.0000000e+00, 6.6575050e-01],\n",
              "        [0.0000000e+00, 7.9889423e-01, 0.0000000e+00, ...,\n",
              "         0.0000000e+00, 0.0000000e+00, 6.6575217e-01],\n",
              "        [0.0000000e+00, 7.9889572e-01, 0.0000000e+00, ...,\n",
              "         0.0000000e+00, 0.0000000e+00, 6.6575032e-01]],\n",
              "\n",
              "       [[0.0000000e+00, 0.0000000e+00, 1.2950947e+00, ...,\n",
              "         2.5639045e-01, 0.0000000e+00, 0.0000000e+00],\n",
              "        [0.0000000e+00, 0.0000000e+00, 1.0316997e+00, ...,\n",
              "         1.9502920e-01, 6.6276707e-02, 0.0000000e+00],\n",
              "        [0.0000000e+00, 0.0000000e+00, 2.7263827e+00, ...,\n",
              "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "        ...,\n",
              "        [0.0000000e+00, 7.9889733e-01, 0.0000000e+00, ...,\n",
              "         0.0000000e+00, 0.0000000e+00, 6.6575050e-01],\n",
              "        [0.0000000e+00, 7.9889423e-01, 0.0000000e+00, ...,\n",
              "         0.0000000e+00, 0.0000000e+00, 6.6575217e-01],\n",
              "        [0.0000000e+00, 7.9889572e-01, 0.0000000e+00, ...,\n",
              "         0.0000000e+00, 0.0000000e+00, 6.6575032e-01]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[4.0165314e-01, 5.2947734e-02, 0.0000000e+00, ...,\n",
              "         2.2018557e+00, 2.6813370e-01, 9.2788005e-01],\n",
              "        [1.2061008e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
              "         0.0000000e+00, 0.0000000e+00, 3.1010920e-01],\n",
              "        [5.6043231e-01, 1.4119227e-01, 7.0981130e-02, ...,\n",
              "         1.3105896e-01, 0.0000000e+00, 5.0878912e-01],\n",
              "        ...,\n",
              "        [0.0000000e+00, 0.0000000e+00, 5.0466204e-01, ...,\n",
              "         0.0000000e+00, 5.9533808e-02, 3.1369495e-01],\n",
              "        [0.0000000e+00, 0.0000000e+00, 1.1233622e+00, ...,\n",
              "         5.5494809e-01, 1.6082175e-01, 6.6790372e-02],\n",
              "        [0.0000000e+00, 0.0000000e+00, 6.7028922e-01, ...,\n",
              "         3.1853199e-01, 1.0215495e-02, 2.9503685e-01]],\n",
              "\n",
              "       [[9.7164643e-01, 2.3203027e+00, 2.6569891e-01, ...,\n",
              "         0.0000000e+00, 7.3757440e-02, 3.9370432e-02],\n",
              "        [0.0000000e+00, 3.9867010e+00, 4.3403012e-01, ...,\n",
              "         0.0000000e+00, 1.3597690e-01, 1.1813222e-01],\n",
              "        [1.6471604e-01, 3.8299327e+00, 3.6666620e-01, ...,\n",
              "         0.0000000e+00, 5.2480325e-02, 3.1087568e-01],\n",
              "        ...,\n",
              "        [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
              "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
              "        [0.0000000e+00, 0.0000000e+00, 1.7545329e-02, ...,\n",
              "         1.5064065e-01, 1.0906303e+00, 1.7418916e+00],\n",
              "        [0.0000000e+00, 7.9889572e-01, 0.0000000e+00, ...,\n",
              "         0.0000000e+00, 0.0000000e+00, 6.6575032e-01]],\n",
              "\n",
              "       [[2.2298299e-01, 0.0000000e+00, 2.1649389e+00, ...,\n",
              "         3.0758488e-01, 0.0000000e+00, 0.0000000e+00],\n",
              "        [0.0000000e+00, 0.0000000e+00, 1.1795571e+00, ...,\n",
              "         0.0000000e+00, 3.0069643e-01, 6.5644584e-03],\n",
              "        [0.0000000e+00, 2.2860797e-01, 2.8504524e+00, ...,\n",
              "         0.0000000e+00, 1.7011128e-01, 0.0000000e+00],\n",
              "        ...,\n",
              "        [0.0000000e+00, 3.0307117e-01, 2.1287885e+00, ...,\n",
              "         0.0000000e+00, 8.4674202e-02, 0.0000000e+00],\n",
              "        [0.0000000e+00, 8.7448597e-02, 2.1915758e+00, ...,\n",
              "         0.0000000e+00, 9.5987320e-04, 0.0000000e+00],\n",
              "        [0.0000000e+00, 1.0793146e-01, 1.1056737e+00, ...,\n",
              "         0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaQCqC5lQO8U",
        "outputId": "7a162bbb-ece1-4724-821a-ed72c0ad6037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 2, 2, 0, 0, 0, 2, 2,\n",
              "       0, 1, 0, 0, 1, 2, 0, 1, 1, 0, 0, 1, 0, 2, 0, 1, 1, 0, 1, 2, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 2, 0, 1, 2, 2, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 2,\n",
              "       2, 1, 1, 1, 0, 1, 1, 2, 1, 2, 0, 1, 1, 0, 1, 2, 1, 1, 0, 2, 1, 1,\n",
              "       2, 0, 0, 2, 0, 1, 0, 0, 0, 2, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 2, 0,\n",
              "       1, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building The Model**"
      ],
      "metadata": {
        "id": "rKczqd9AT0zE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MobileLSTM model\n",
        "def create_mobilelstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, return_sequences=True, input_shape=input_shape))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(LSTM(64, return_sequences=False))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "rsT1EaDz40FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Spark Pipeline**"
      ],
      "metadata": {
        "id": "a02EsfVWT5m0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, ArrayType, FloatType, IntegerType\n",
        "# Train\n",
        "# Convert y_train to float\n",
        "y_train = y_train.astype(np.float32)\n",
        "\n",
        "# Convert numpy arrays to lists of tuples\n",
        "data_train = [(X_train[i].tolist(), float(y_train[i])) for i in range(len(X_train))]\n",
        "\n",
        "# Define schema for the DataFrame\n",
        "schema = StructType([\n",
        "    StructField(\"features_train\", ArrayType(ArrayType(FloatType())), True),\n",
        "    StructField(\"labels_train\", FloatType(), True)\n",
        "])\n",
        "\n",
        "# Create DataFrame\n",
        "train_df = spark.createDataFrame(data_train, schema)\n",
        "\n",
        "# #Test\n",
        "# Convert y_test to float\n",
        "y_test = y_test.astype(np.float32)\n",
        "\n",
        "# Convert numpy arrays to lists of tuples\n",
        "data_test = [(X_test[i].tolist(), float(y_test[i])) for i in range(len(X_test))]\n",
        "\n",
        "# Define schema for the DataFrame\n",
        "schema = StructType([\n",
        "    StructField(\"features_test\", ArrayType(ArrayType(FloatType())), True),\n",
        "    StructField(\"labels_test\", FloatType(), True)\n",
        "])\n",
        "\n",
        "# Create DataFrame\n",
        "test_df = spark.createDataFrame(data_test, schema)\n"
      ],
      "metadata": {
        "id": "RVoEqEkyyQHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.show()\n",
        "test_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTg34ULSRWIV",
        "outputId": "9670af9a-eb74-47b9-d41d-47620421f61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------+\n",
            "|      features_train|labels_train|\n",
            "+--------------------+------------+\n",
            "|[[1.0606327, 0.0,...|         1.0|\n",
            "|[[0.0, 0.0, 0.0, ...|         1.0|\n",
            "|[[0.0, 0.0, 1.295...|         0.0|\n",
            "|[[0.0, 0.00719769...|         1.0|\n",
            "|[[0.0, 0.9712226,...|         0.0|\n",
            "|[[0.24123171, 0.1...|         1.0|\n",
            "|[[0.0, 0.0, 0.104...|         0.0|\n",
            "|[[0.0, 2.2483082,...|         0.0|\n",
            "|[[0.0, 0.01189200...|         0.0|\n",
            "|[[0.0, 0.0, 0.017...|         1.0|\n",
            "|[[0.6432096, 0.09...|         0.0|\n",
            "|[[0.0, 0.07047849...|         1.0|\n",
            "|[[0.15117094, 0.0...|         0.0|\n",
            "|[[0.0, 0.09764412...|         1.0|\n",
            "|[[0.0, 0.0, 2.111...|         0.0|\n",
            "|[[0.0, 0.0, 0.0, ...|         2.0|\n",
            "|[[0.8973733, 0.0,...|         2.0|\n",
            "|[[0.03134775, 1.1...|         0.0|\n",
            "|[[0.0, 0.0, 0.359...|         0.0|\n",
            "|[[0.0, 0.90706986...|         0.0|\n",
            "+--------------------+------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------------------+-----------+\n",
            "|       features_test|labels_test|\n",
            "+--------------------+-----------+\n",
            "|[[1.0547994, 0.0,...|        1.0|\n",
            "|[[0.0, 0.01830535...|        0.0|\n",
            "|[[0.0, 0.0, 1.003...|        2.0|\n",
            "|[[0.17031008, 2.7...|        1.0|\n",
            "|[[0.0, 0.20482047...|        1.0|\n",
            "|[[0.0, 0.0, 0.003...|        1.0|\n",
            "|[[0.0, 0.0, 1.601...|        0.0|\n",
            "|[[0.025356928, 0....|        1.0|\n",
            "|[[0.03836049, 0.7...|        2.0|\n",
            "|[[0.0, 1.3304558,...|        0.0|\n",
            "|[[0.0, 0.0, 0.0, ...|        0.0|\n",
            "|[[0.0, 0.617005, ...|        2.0|\n",
            "|[[0.0, 0.0, 0.315...|        0.0|\n",
            "+--------------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[labels, features, model])\n",
        "\n",
        "fitted_pipeline = pipeline.fit(train_df)\n",
        "prediction = fitted_pipeline.transform(train_df)\n",
        "prediction = fitted_pipeline.transform(test_df)"
      ],
      "metadata": {
        "id": "TN2yUafCxj8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "model = create_mobilelstm_model(input_shape)"
      ],
      "metadata": {
        "id": "TM2Gx3NBKdX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "kKRDRzZCKeLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Specifying Callbacks and Fitting**"
      ],
      "metadata": {
        "id": "0nsQe26jUHEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg3cYKaRKf0M",
        "outputId": "27082946-9841-4616-def2-43bb10a5f5e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 6s 408ms/step - loss: 1.0522 - accuracy: 0.3894 - val_loss: 0.9146 - val_accuracy: 0.6154\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.9177 - accuracy: 0.5487 - val_loss: 0.7472 - val_accuracy: 0.7692\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.8032 - accuracy: 0.6195 - val_loss: 0.5846 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.6996 - accuracy: 0.6814 - val_loss: 0.4703 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.5866 - accuracy: 0.7788 - val_loss: 0.4672 - val_accuracy: 0.7692\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.5187 - accuracy: 0.7876 - val_loss: 0.3236 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 56ms/step - loss: 0.4075 - accuracy: 0.8761 - val_loss: 0.3342 - val_accuracy: 0.7692\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 66ms/step - loss: 0.3557 - accuracy: 0.8761 - val_loss: 0.2752 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.3127 - accuracy: 0.9027 - val_loss: 0.3982 - val_accuracy: 0.6923\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.2063 - accuracy: 0.9558 - val_loss: 0.2946 - val_accuracy: 0.9231\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b34fa22fc70>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu5fzChrKiDA",
        "outputId": "d4ad6ef2-1202-4399-f2a3-d62fb0b12d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2946 - accuracy: 0.9231\n",
            "Test Accuracy: 92.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions (optional)\n",
        "predictions = model.predict(X_test)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Save the model (optional)\n",
        "model.save('/content/drive/MyDrive/BigData/MobileLSTM_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwkmOnHgKket",
        "outputId": "d1a1c7ef-25b2-499e-9b4d-9c1392392d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load the pre-trained MobileLSTM model\n",
        "MobileLSTM_model = load_model('/content/drive/MyDrive/BigData/MobileLSTM_model.h5')\n",
        "\n",
        "# Define the image height and width based on your model's input requirements\n",
        "IMAGE_HEIGHT = 75\n",
        "IMAGE_WIDTH = 75\n",
        "\n",
        "# Define the classes list\n",
        "CLASSES_LIST = ['Class 0 - Safe', 'Class 1 - Fantasy Violence', 'Class 2 - Sex, Nudity']"
      ],
      "metadata": {
        "id": "olhUXo6-Lie7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MobileNetV2 model for feature extraction, excluding the top layer\n",
        "feature_extractor = MobileNetV2(weights='imagenet', include_top=False, pooling='avg', input_shape=(75, 75, 3))\n",
        "def extract_features(frames):\n",
        "    # Preprocess frames for MobileNetV2\n",
        "    frames = np.array([cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH)) for frame in frames])\n",
        "    frames = frames / 255.0  # Normalize the frames\n",
        "    features = feature_extractor.predict(frames)\n",
        "    return features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doYdkoBzMG3G",
        "outputId": "45592de4-a97d-4c4d-ff2e-28a077a2ac31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_video(video_file_path, SEQUENCE_LENGTH):\n",
        "    video_reader = cv2.VideoCapture(video_file_path)\n",
        "\n",
        "    # Get the width and height of the video.\n",
        "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Declare a list to store video frames we will extract.\n",
        "    frames_list = []\n",
        "\n",
        "    # Get the number of frames in the video.\n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calculate the interval after which frames will be added to the list.\n",
        "    skip_frames_window = max(int(video_frames_count / SEQUENCE_LENGTH), 1)\n",
        "\n",
        "    # Iterating the number of times equal to the fixed length of sequence.\n",
        "    for frame_counter in range(SEQUENCE_LENGTH):\n",
        "        # Set the current frame position of the video.\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "\n",
        "        success, frame = video_reader.read()\n",
        "\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Append the frame to the frames list\n",
        "        frames_list.append(frame)\n",
        "\n",
        "    # Extract features from the frames using MobileNetV2\n",
        "    frames_features = extract_features(frames_list)\n",
        "\n",
        "    # Expand dimensions to match model input shape\n",
        "    frames_features = np.expand_dims(frames_features, axis=0)\n",
        "\n",
        "    # Passing the pre-processed frames to the model and get the predicted probabilities.\n",
        "    predicted_labels_probabilities = MobileLSTM_model.predict(frames_features)[0]\n",
        "\n",
        "    # Get the index of class with highest probability.\n",
        "    predicted_label = np.argmax(predicted_labels_probabilities)\n",
        "\n",
        "    # Get the class name using the retrieved index.\n",
        "    predicted_class_name = CLASSES_LIST[predicted_label]\n",
        "\n",
        "    # Display the predicted class along with the prediction confidence.\n",
        "    print(f'Predicted: {predicted_class_name}\\nConfidence: {predicted_labels_probabilities[predicted_label]}')\n",
        "\n",
        "    video_reader.release()"
      ],
      "metadata": {
        "id": "YQLNfuGPJnVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction For The Video**"
      ],
      "metadata": {
        "id": "gRteEyCLUYQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "SEQUENCE_LENGTH = 16\n",
        "# Specifying video to be predicted\n",
        "input_video_file_path = \"/content/drive/MyDrive/BigData/Class 0 - Safe/Video_31.mp4\"\n",
        "\n",
        "# Perform Single Prediction on the Test Video.\n",
        "predict_video(input_video_file_path, SEQUENCE_LENGTH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGJDrEhJJrfI",
        "outputId": "e4943174-0ce4-4eff-c692-8095fcab1b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Predicted: Class 0 - Safe\n",
            "Confidence: 0.9015423059463501\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}